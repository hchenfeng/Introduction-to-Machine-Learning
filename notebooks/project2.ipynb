{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### By Chenfeng (Aaron) Hao\n",
    "\n",
    "In this exercise, we are building a naive bayes classifier for tagging documents. The data we use are text documents on 20 topics, consisting of 11292 records for training and 7157 records for testing. The classifier is supposed to learn the conditional probability of what topic a document is on based on which words appear in the training data for a particular topic. We then use the probability learned from the training data to predict the topic of documents in the testing data.\n",
    "\n",
    "The resulting model shows an overall accuracy of 81%, which is not much different from that of a vanilla sklearn MultinomialNB classifier with little additional processing (79.8% accuracy)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load train/test data from files\n",
    "train_file_data = pd.read_fwf(\"../data/forumTraining.data\", delimiter=\"\\n\")\n",
    "test_file_data = pd.read_fwf(\"../data/forumTest.data\", delimiter=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# separate topic from document by adding an extra column\n",
    "train_data = train_file_data.iloc[:,0].str.split(n=1, expand=True)\n",
    "test_data = test_file_data.iloc[:,0].str.split(n=1, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are many clean-ups we can perform on the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import gensim\n",
    "import spacy\n",
    "\n",
    "# get stop words from three sources\n",
    "\n",
    "stopwords_gensim = gensim.parsing.preprocessing.STOPWORDS\n",
    "\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "stopwords_spacy = sp.Defaults.stop_words\n",
    "\n",
    "stopwords_nltk = stopwords.words(\"english\")\n",
    "\n",
    "# extend the stop words list\n",
    "stopwords_nltk.extend(['cannot', 'could', 'done', 'let', 'may' 'mayn',  'might',  'must', 'need', 'ought', 'oughtn', 'shall', 'would', 'br', 'faq', 'alt', 'co', 'uk', 'whilst', 'pgp', 'signed', 'he', 'please', 'edu', 'cs', 'umd', 'et', 'al', 'her'])\n",
    "\n",
    "stop_words = stopwords_gensim.union(set(stopwords_nltk))\n",
    "\n",
    "stop_words = stop_words.union(set(stopwords_spacy))\n",
    "\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    This function preprocesses the data for analysis.\n",
    "    :param text: a piece of text\n",
    "    :return: processed text\n",
    "    \"\"\"\n",
    "    # split text into words\n",
    "    # str.split() is faster than nltk tokenize\n",
    "    # since punctuations are removed already, we don't need tokenize\n",
    "    word_tokens = text.split()\n",
    "\n",
    "    # remove stop words\n",
    "    #filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "\n",
    "    # remove single letters/numbers\n",
    "    #filtered_text = [re.sub(r'\\b\\w{1,2}\\b', '', word) for word in filtered_text]\n",
    "\n",
    "    # remove empty string resulted from the last step\n",
    "    #filtered_text = list(filter(None, filtered_text))\n",
    "\n",
    "    #filtered_text = [stemmer.stem(word) for word in filtered_text]\n",
    "\n",
    "    #filtered_text = [lemmatizer.lemmatize(word) for word in filtered_text]\n",
    "    return word_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "test_df = test_data\n",
    "#test_df.columns = ['topic', 'wordlist']\n",
    "test_df[1] = test_df.apply(lambda row: preprocess(row[1]), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "train_df = train_data\n",
    "#train_df.columns = ['topic', 'wordlist']\n",
    "train_df[1] = train_df.apply(lambda row: preprocess(row[1]), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "['re',\n 'yet',\n 'more',\n 'rushdie',\n 're',\n 'islamic',\n 'law',\n 'jaeger',\n 'buphy',\n 'bu',\n 'edu',\n 'gregg',\n 'jaeger',\n 'writes',\n 'in',\n 'article',\n 'vice',\n 'ico',\n 'tek',\n 'com',\n 'bobbe',\n 'vice',\n 'ico',\n 'tek',\n 'com',\n 'robert',\n 'beauchaine',\n 'writes',\n 'bennett',\n 'neil',\n 'how',\n 'bcci',\n 'adapted',\n 'the',\n 'koran',\n 'rules',\n 'of',\n 'banking',\n 'the',\n 'times',\n 'august',\n 'so',\n 'let',\n 's',\n 'see',\n 'if',\n 'some',\n 'guy',\n 'writes',\n 'a',\n 'piece',\n 'with',\n 'a',\n 'title',\n 'that',\n 'implies',\n 'something',\n 'is',\n 'the',\n 'case',\n 'then',\n 'it',\n 'must',\n 'be',\n 'so',\n 'is',\n 'that',\n 'it',\n 'gregg',\n 'you',\n 'haven',\n 't',\n 'provided',\n 'even',\n 'a',\n 'title',\n 'of',\n 'an',\n 'article',\n 'to',\n 'support',\n 'your',\n 'contention',\n 'this',\n 'is',\n 'how',\n 'you',\n 'support',\n 'a',\n 'position',\n 'if',\n 'you',\n 'intend',\n 'to',\n 'have',\n 'anyone',\n 'respect',\n 'it',\n 'gregg',\n 'any',\n 'questions',\n 'and',\n 'i',\n 'even',\n 'managed',\n 'to',\n 'include',\n 'the',\n 'above',\n 'reference',\n 'with',\n 'my',\n 'head',\n 'firmly',\n 'engaged',\n 'in',\n 'my',\n 'ass',\n 'what',\n 's',\n 'your',\n 'excuse',\n 'this',\n 'supports',\n 'nothing',\n 'i',\n 'have',\n 'no',\n 'reason',\n 'to',\n 'believe',\n 'that',\n 'this',\n 'is',\n 'piece',\n 'is',\n 'anything',\n 'other',\n 'than',\n 'another',\n 'anti',\n 'islamic',\n 'slander',\n 'job',\n 'you',\n 'also',\n 'have',\n 'no',\n 'reason',\n 'to',\n 'believe',\n 'it',\n 'is',\n 'an',\n 'anti',\n 'islamic',\n 'slander',\n 'job',\n 'apart',\n 'from',\n 'your',\n 'own',\n 'prejudices',\n 'i',\n 'have',\n 'no',\n 'respect',\n 'for',\n 'titles',\n 'only',\n 'for',\n 'real',\n 'content',\n 'i',\n 'can',\n 'look',\n 'up',\n 'this',\n 'article',\n 'if',\n 'i',\n 'want',\n 'true',\n 'but',\n 'i',\n 'can',\n 'tell',\n 'you',\n 'bcci',\n 'was',\n 'not',\n 'an',\n 'islamic',\n 'bank',\n 'why',\n 'yes',\n 'what',\n 's',\n 'a',\n 'mere',\n 'report',\n 'in',\n 'the',\n 'times',\n 'stating',\n 'that',\n 'bcci',\n 'followed',\n 'islamic',\n 'banking',\n 'rules',\n 'gregg',\n 'knows',\n 'islam',\n 'is',\n 'good',\n 'and',\n 'he',\n 'knows',\n 'bcci',\n 'were',\n 'bad',\n 'therefore',\n 'bcci',\n 'cannot',\n 'have',\n 'been',\n 'islamic',\n 'anyone',\n 'who',\n 'says',\n 'otherwise',\n 'is',\n 'obviously',\n 'spreading',\n 'slanderous',\n 'propaganda',\n 'if',\n 'someone',\n 'wants',\n 'to',\n 'discuss',\n 'the',\n 'issue',\n 'more',\n 'seriously',\n 'then',\n 'i',\n 'd',\n 'be',\n 'glad',\n 'to',\n 'have',\n 'a',\n 'real',\n 'discussion',\n 'providing',\n 'references',\n 'etc',\n 'i',\n 'see',\n 'if',\n 'someone',\n 'wants',\n 'to',\n 'provide',\n 'references',\n 'to',\n 'articles',\n 'you',\n 'agree',\n 'with',\n 'you',\n 'will',\n 'also',\n 'respond',\n 'with',\n 'references',\n 'to',\n 'articles',\n 'you',\n 'agree',\n 'with',\n 'mmm',\n 'yes',\n 'that',\n 'would',\n 'be',\n 'a',\n 'very',\n 'intellectually',\n 'stimulating',\n 'debate',\n 'doubtless',\n 'that',\n 's',\n 'how',\n 'you',\n 'spend',\n 'your',\n 'time',\n 'in',\n 'soc',\n 'culture',\n 'islam',\n 'i',\n 've',\n 'got',\n 'a',\n 'special',\n 'place',\n 'for',\n 'you',\n 'in',\n 'my',\n 'kill',\n 'file',\n 'right',\n 'next',\n 'to',\n 'bobby',\n 'want',\n 'to',\n 'join',\n 'him',\n 'the',\n 'more',\n 'you',\n 'post',\n 'the',\n 'more',\n 'i',\n 'become',\n 'convinced',\n 'that',\n 'it',\n 'is',\n 'simply',\n 'a',\n 'waste',\n 'of',\n 'time',\n 'to',\n 'try',\n 'and',\n 'reason',\n 'with',\n 'moslems',\n 'is',\n 'that',\n 'what',\n 'you',\n 'are',\n 'hoping',\n 'to',\n 'achieve',\n 'mathew']"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[1][1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def train_naive_bayes(df):\n",
    "    vocabulary = set(np.concatenate(df[1]))\n",
    "    topic_dict = dict(train_df.groupby(df[0]).size().div(len(df)))\n",
    "\n",
    "    new_df = df.groupby(df[0], as_index = False).agg(sum)\n",
    "\n",
    "    total_n_of_vocabulary = len(vocabulary)\n",
    "    topic_list = list(new_df[0])\n",
    "    word_position = {topic: len(new_df[new_df[0] == topic][1].item()) for topic in topic_list}\n",
    "    sum_n_len_vocab = {k: v+total_n_of_vocabulary for k,v in word_position.items()}\n",
    "    vocab_dict = {topic: {} for topic in topic_list}\n",
    "\n",
    "    for topic in topic_list:\n",
    "        all_words = {word: 0 for word in vocabulary}\n",
    "        index = new_df[0] == topic\n",
    "        vocab_dict[topic] = all_words\n",
    "        topic_counter = Counter(new_df[index][1].item())\n",
    "        vocab_dict[topic].update(topic_counter)\n",
    "        vocab_dict[topic] = {k:(v+1)/sum_n_len_vocab[topic] for k,v in vocab_dict[topic].items()}\n",
    "\n",
    "    return vocabulary, vocab_dict, topic_list, topic_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "result = train_naive_bayes(train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "vocabulary, vocab_dict, topic_list, topic_dict = result[0], result[1], result[2], result[3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "0       [re, amusing, atheists, and, agnostics, in, ar...\n1       [re, yet, more, rushdie, re, islamic, law, jae...\n2       [re, christian, morality, is, in, article, vic...\n3       [re, after, years, can, we, say, that, christi...\n4       [re, amusing, atheists, and, agnostics, timmba...\n                              ...                        \n7522    [re, religion, and, marriage, pboxrud, magnus,...\n7523    [re, a, message, for, you, mr, president, how,...\n7524    [re, why, did, they, behave, as, they, did, wa...\n7525    [re, info, about, new, age, in, article, apr, ...\n7526    [re, i, ll, see, your, demand, and, raise, you...\nName: 1, Length: 7527, dtype: object"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "def predict(data, vocabulary, vocab_dict, topic_list, topic_dict):\n",
    "    prob_dict = {}\n",
    "    predictions = []\n",
    "    for i in range(0, len(data)-1):\n",
    "        wordlist = data[i]\n",
    "        for topic in topic_list:\n",
    "            x = np.array([vocab_dict[topic][word] for word in wordlist if word in vocabulary])\n",
    "            prod_word = np.prod(x, dtype='float128')\n",
    "            prob_dict[topic] = np.prod([prod_word, topic_dict[topic]], dtype='float128')\n",
    "            predictions.append(max(prob_dict, key=prob_dict.get))\n",
    "    return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "predictions = predict(test_df[1], vocabulary, vocab_dict, topic_list, topic_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "result_df = test_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "result_df['prediction'] = result_df.apply(lambda row: predict(row[1], vocabulary, vocab_dict, topic_list, topic_dict), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "result_df['correct'] = result_df.apply(lambda row: row.prediction == row[0], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7989903015809752"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = np.sum(result_df.correct)/len(result_df)\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "def calc_precision(confusion_matrix, topic):\n",
    "    return confusion_matrix[topic][topic]/confusion_matrix[topic][len(confusion_matrix) - 1]\n",
    "\n",
    "def calc_recall(confusion_matrix, topic):\n",
    "    return confusion_matrix[topic][topic]/confusion_matrix.loc[topic][len(confusion_matrix) - 1]\n",
    "\n",
    "def get_precision_recall(df, topic_list):\n",
    "    confusion_matrix = pd.crosstab(df[0], df['prediction'], rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "    precision = [calc_precision(confusion_matrix, topic) for topic in topic_list]\n",
    "    recall = [calc_recall(confusion_matrix, topic) for topic in topic_list]\n",
    "    pr_df = pd.DataFrame(zip(topic_list, precision, recall), columns=['topic', 'precision', 'recall'])\n",
    "    return pr_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "              topic  precision    recall\n0           atheism   0.746032  0.738994\n1             autos   0.831050  0.921519\n2          baseball   0.975342  0.896725\n3      christianity   0.672535  0.959799\n4        cryptology   0.745491  0.939394\n5       electronics   0.801242  0.656489\n6           forsale   0.934363  0.620513\n7          graphics   0.728205  0.730077\n8              guns   0.679359  0.931319\n9            hockey   0.957921  0.969925\n10              mac   0.838806  0.729870\n11         medicine   0.901907  0.835859\n12  mideastpolitics   0.897297  0.882979\n13      motorcycles   0.944737  0.902010\n14        mswindows   0.840678  0.629442\n15               pc   0.603846  0.801020\n16         politics   0.564815  0.590323\n17         religion   0.890000  0.354582\n18            space   0.873711  0.860406\n19         xwindows   0.820051  0.813776",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>atheism</td>\n      <td>0.746032</td>\n      <td>0.738994</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>autos</td>\n      <td>0.831050</td>\n      <td>0.921519</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>baseball</td>\n      <td>0.975342</td>\n      <td>0.896725</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>christianity</td>\n      <td>0.672535</td>\n      <td>0.959799</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cryptology</td>\n      <td>0.745491</td>\n      <td>0.939394</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>electronics</td>\n      <td>0.801242</td>\n      <td>0.656489</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>forsale</td>\n      <td>0.934363</td>\n      <td>0.620513</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>graphics</td>\n      <td>0.728205</td>\n      <td>0.730077</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>guns</td>\n      <td>0.679359</td>\n      <td>0.931319</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>hockey</td>\n      <td>0.957921</td>\n      <td>0.969925</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>mac</td>\n      <td>0.838806</td>\n      <td>0.729870</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>medicine</td>\n      <td>0.901907</td>\n      <td>0.835859</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>mideastpolitics</td>\n      <td>0.897297</td>\n      <td>0.882979</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>motorcycles</td>\n      <td>0.944737</td>\n      <td>0.902010</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>mswindows</td>\n      <td>0.840678</td>\n      <td>0.629442</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>pc</td>\n      <td>0.603846</td>\n      <td>0.801020</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>politics</td>\n      <td>0.564815</td>\n      <td>0.590323</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>religion</td>\n      <td>0.890000</td>\n      <td>0.354582</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>space</td>\n      <td>0.873711</td>\n      <td>0.860406</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>xwindows</td>\n      <td>0.820051</td>\n      <td>0.813776</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_precision_recall(result_df,topic_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, I used the MultinomialNB classifier from sklearn as a benchmark."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "#train_data = train_file_data.iloc[:,0].str.split(n=1, expand=True)\n",
    "#test_data = test_file_data.iloc[:,0].str.split(n=1, expand=True)\n",
    "\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#count_vect = CountVectorizer()\n",
    "#mnb = MultinomialNB()\n",
    "\n",
    "#X_train = count_vect.fit_transform(train_data[1])\n",
    "\n",
    "#y_train = np.array(train_data[0])\n",
    "#X_test = count_vect.transform(test_data[1])\n",
    "#y_test = np.array(test_data[0])\n",
    "#clf = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "#y_pred = clf.predict(X_test)\n",
    "\n",
    "#from sklearn import metrics\n",
    "#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#conf_mat = confusion_matrix(y_test, y_pred)\n",
    "#conf_mat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "#from sklearn.metrics import precision_recall_fscore_support\n",
    "#precision_recall_fscore_support(y_test, y_pred, average=None)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}