{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this exercise, we are building a naive bayes classifier for tagging documents. The data we use are text documents on 20 topics, consisting of 11293 records for training and 7528 records for testing. The classifier is supposed to learn the conditional probability of what topic a document is about based on which words appear in the training data for the topics. We then use the probability learned from the training data to predict the topic of documents in the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading and Preprocessing Data\n",
    "\n",
    "The data are texts delimited by line separators: each line is a document on a topic. The first letter of a document indicates the topic it is on."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use pd.read_fwf() to save the data into a Pandas Dataframe. Using readlines() may give us more control over how we want to read in the data. However, since our data consists of only text documents, pd.read_fwf() with minimal additional arguments should suffice."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load train/test data from files\n",
    "train_file_data = pd.read_fwf(\"../data/forumTraining.data\", header=None, delimiter=\"\\n\")\n",
    "test_file_data = pd.read_fwf(\"../data/forumTest.data\", header=None, delimiter=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use str.split() to put the first letter of each document into a new column and the rest into a second."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# separate topic from document by adding an extra column\n",
    "train_data = train_file_data.iloc[:,0].str.split(n=1, expand=True)\n",
    "test_data = test_file_data.iloc[:,0].str.split(n=1, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The documents are already processed: punctuations are all removed and letters converted to lowercase. In addition, we remove stop words--words such as common adverbs (afterwards, everywhere, still, etc.), articles (the/a/an), pronouns (I, we, you, etc.)--from the documents, because they are more functional and convey less meaning, which makes them less useful for our purpose. We also remove words consisting of only 1 or 2 letters, because we can confirm that they do not contribute meaningful concepts to any documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# get a list of words consisting of less than 3 letters\n",
    "# [word for word in set(np.concatenate(train_data[1].str.split())) if len(word) < 3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The stop words list is obtained from combining lists from three sources: nltk, gensim, and spacy."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "import spacy\n",
    "\n",
    "# get stop words from three sources (gensim, spacy, nltk)\n",
    "stopwords_gensim = gensim.parsing.preprocessing.STOPWORDS\n",
    "\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "stopwords_spacy = sp.Defaults.stop_words\n",
    "\n",
    "stopwords_nltk = stopwords.words(\"english\")\n",
    "\n",
    "# extend the stop words list\n",
    "stopwords_nltk.extend(['cannot', 'could', 'done', 'let', 'may' 'mayn',  'might',  'must', 'need', 'ought', 'oughtn', 'shall', 'would', 'br', 'faq', 'alt', 'co', 'uk', 'whilst', 'pgp', 'signed', 'he', 'please', 'edu', 'cs', 'umd', 'et', 'al', 'her', 'com', 'like', 'apr'])\n",
    "\n",
    "# combine the stopwords lists\n",
    "stop_words = stopwords_gensim.union(set(stopwords_nltk))\n",
    "stop_words = stop_words.union(set(stopwords_spacy))\n",
    "\n",
    "def preprocess(df):\n",
    "    # split words\n",
    "    filtered_text = df.str.split()\n",
    "\n",
    "    # filter stopwords\n",
    "    filtered_text = filtered_text.apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "    # filter words with less than three letters\n",
    "    filtered_text = filtered_text.apply(lambda x: [word for word in x if len(word) > 2 ])\n",
    "\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# apply the above text cleaning to both train and test data\n",
    "\n",
    "train_df = train_data\n",
    "train_df[1] = preprocess(train_df[1])\n",
    "\n",
    "test_df = test_data\n",
    "test_df[1] = preprocess(test_df[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We explore the most frequent words for each topic. If we like, we may add frequent words we think are irrelevant to the stop words list."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[('god', 707),\n ('people', 573),\n ('writes', 563),\n ('article', 409),\n ('think', 390),\n ('atheists', 310),\n ('atheism', 301),\n ('know', 275),\n ('believe', 249),\n ('religion', 220),\n ('time', 216),\n ('said', 210),\n ('islam', 203),\n ('evidence', 202),\n ('way', 192),\n ('morality', 192),\n ('keith', 191),\n ('good', 186),\n ('moral', 184),\n ('argument', 184)]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group documents by topic\n",
    "df = train_df.groupby(train_df[0], as_index = False).agg(list)\n",
    "df[1] = df[1].apply(np.concatenate)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# get top frequent words\n",
    "Counter(df[1][0]).most_common(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As an option, we may create a word frequency chart for the same purpose as above. For example, the following chart shows the top 20 words in all \"atheism\" documents."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     god   people   writes  article    think atheists  atheism     know  believe religion     time     said    islam evidence      way morality    keith     good    moral argument \n",
      "     707      573      563      409      390      310      301      275      249      220      216      210      203      202      192      192      191      186      184      184 \n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "words_freq = FreqDist(df[1][0])\n",
    "words_freq.plot(20, title=\"Most frequent words\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training\n",
    "\n",
    "We have the naive bayes model learn word probabilities as specified in the project specification document. we use a set to contain all unique words in all documents. The probabilities of topics (N(documents) of a topic/N(all documents)) are stored in a dictionary named topic_dict. The word probabilities given a particular topic are stored in vocab_dict. We use Laplace smoothing (add 1 to word frequency count) to deal with zero probability. For modularity, a few other relevant variables are returned from the same function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from numba import jit\n",
    "\n",
    "# @jit()\n",
    "def train_naive_bayes(df):\n",
    "    # get vocabulary from all words\n",
    "    vocabulary = set(np.concatenate(df[1]))\n",
    "\n",
    "    # get word count to simplify calculation\n",
    "    total_n_of_vocabulary = len(vocabulary)\n",
    "\n",
    "    # get topic_count/document_count for all topics\n",
    "    topic_dict = dict(df.groupby(df[0]).size().div(len(df)))\n",
    "\n",
    "    # get new df grouped by topic\n",
    "    new_df = df.groupby(df[0], as_index = False).agg(list)\n",
    "\n",
    "    # concatenate lists for the same topic from previous grouping\n",
    "    new_df[1] = new_df[1].apply(np.concatenate)\n",
    "\n",
    "    # get list of topics\n",
    "    topic_list = list(set(new_df[0]))\n",
    "\n",
    "    # get number of word positions for each topic\n",
    "    word_position = {topic: len(new_df[new_df[0] == topic][1].item()) for topic in topic_list}\n",
    "\n",
    "    # get the sum of word position and total vocabulary count for each topic\n",
    "    sum_n_len_vocab = {k: v+total_n_of_vocabulary for k,v in word_position.items()}\n",
    "\n",
    "    # initialize empty dictionary to store word probabilities in each topic\n",
    "    vocab_dict = {topic: {} for topic in topic_list}\n",
    "    for topic in topic_list:\n",
    "        # initialize a topic with 0 as count values for all words\n",
    "        vocab_dict[topic] = {word: 0 for word in vocabulary}\n",
    "\n",
    "        # get index for a topic\n",
    "        index = new_df[0] == topic\n",
    "\n",
    "        # count word occurrence\n",
    "        topic_counter = Counter(new_df[index][1].item())\n",
    "\n",
    "        # use word count to update dictionary items of the topic\n",
    "        vocab_dict[topic].update(topic_counter)\n",
    "\n",
    "        # add 1 to word count to avoid 0 probability, calculate the word probability in a document\n",
    "        vocab_dict[topic] = {k:(v+1)/sum_n_len_vocab[topic] for k,v in vocab_dict[topic].items()}\n",
    "\n",
    "    return vocab_dict, vocabulary, topic_dict, topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train model and get results\n",
    "\n",
    "training_result = train_naive_bayes(train_df)\n",
    "\n",
    "vocab_dict, vocabulary, topic_dict, topic_list = training_result[0], training_result[1], training_result[2], training_result[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Testing\n",
    "\n",
    "The fact that probabilities are stored in dictionaries makes retrieving them easy.\n",
    "\n",
    "In the prediction/classification step, we implement\n",
    "\n",
    "$$ C_{NB}=\\max \\limits _{c _{j} \\in C}\\left(P(c _{j}) \\prod \\limits_{i \\in Positions} ùëÉ(a _{i}|c _{j})\\right) $$\n",
    "\n",
    "To deal with underflow (multiplying very small floats), we choose to specify dtype as 'float128', instead of using log. This way we avoid the step of converting probabilities to their log, hoping to improve performance, although the improvement is not that obvious for our data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@jit()\n",
    "def predict(df, vocab_dict, vocabulary, topic_dict, topic_list):\n",
    "    predictions = []\n",
    "    for row in df.iterrows():\n",
    "        wordlist = row[1][1]\n",
    "        preds = []\n",
    "        for topic in topic_list:\n",
    "            # put probabilities of found words in np array\n",
    "            x = np.array([vocab_dict[topic][word] for word in wordlist if word in vocabulary])\n",
    "\n",
    "            # get the product of the probabilities\n",
    "            prod_word = np.prod(x, dtype='float128')\n",
    "\n",
    "            # get the product of topic probability and words probability, add the result to list\n",
    "            preds.append(np.prod([prod_word, topic_dict[topic]], dtype='float128'))\n",
    "\n",
    "        # add the topic with the highest probability to prediction\n",
    "        pred = topic_list[np.argmax(np.array(preds))]\n",
    "        predictions.append(pred)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-27-d80d19091de1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0ma\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0mpredictions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvocab_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvocabulary\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtopic_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtopic_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'timeit'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'a()'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/GVSU-CIS678/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mrun_line_magic\u001B[0;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[1;32m   2325\u001B[0m                 \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'local_ns'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_local_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstack_depth\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2326\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuiltin_trap\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2327\u001B[0;31m                 \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2328\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2329\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<decorator-gen-53>\u001B[0m in \u001B[0;36mtimeit\u001B[0;34m(self, line, cell, local_ns)\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/GVSU-CIS678/lib/python3.8/site-packages/IPython/core/magic.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(f, *a, **k)\u001B[0m\n\u001B[1;32m    185\u001B[0m     \u001B[0;31m# but it's overkill for just that one bit of state.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    186\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mmagic_deco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 187\u001B[0;31m         \u001B[0mcall\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mlambda\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    188\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    189\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcallable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/GVSU-CIS678/lib/python3.8/site-packages/IPython/core/magics/execution.py\u001B[0m in \u001B[0;36mtimeit\u001B[0;34m(self, line, cell, local_ns)\u001B[0m\n\u001B[1;32m   1167\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mindex\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1168\u001B[0m                 \u001B[0mnumber\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m10\u001B[0m \u001B[0;34m**\u001B[0m \u001B[0mindex\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1169\u001B[0;31m                 \u001B[0mtime_number\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtimer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtimeit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnumber\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1170\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mtime_number\u001B[0m \u001B[0;34m>=\u001B[0m \u001B[0;36m0.2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1171\u001B[0m                     \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/GVSU-CIS678/lib/python3.8/site-packages/IPython/core/magics/execution.py\u001B[0m in \u001B[0;36mtimeit\u001B[0;34m(self, number)\u001B[0m\n\u001B[1;32m    167\u001B[0m         \u001B[0mgc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdisable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    168\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 169\u001B[0;31m             \u001B[0mtiming\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minner\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtimer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    170\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    171\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mgcold\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<magic-timeit>\u001B[0m in \u001B[0;36minner\u001B[0;34m(_it, _timer)\u001B[0m\n",
      "\u001B[0;32m<ipython-input-27-d80d19091de1>\u001B[0m in \u001B[0;36ma\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# get predictions\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0ma\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mpredictions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvocab_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvocabulary\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtopic_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtopic_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'timeit'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'a()'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/GVSU-CIS678/lib/python3.8/site-packages/numba/core/dispatcher.py\u001B[0m in \u001B[0;36m_compile_for_args\u001B[0;34m(self, *args, **kws)\u001B[0m\n\u001B[1;32m    363\u001B[0m                 \u001B[0margtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOmitted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    364\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 365\u001B[0;31m                 \u001B[0margtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtypeof_pyval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    366\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    367\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtuple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margtypes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/GVSU-CIS678/lib/python3.8/site-packages/numba/core/dispatcher.py\u001B[0m in \u001B[0;36mtypeof_pyval\u001B[0;34m(self, val)\u001B[0m\n\u001B[1;32m    636\u001B[0m         \u001B[0;31m# can save a couple ¬µs.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    637\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 638\u001B[0;31m             \u001B[0mtp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtypeof\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mPurpose\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margument\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    639\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    640\u001B[0m             \u001B[0mtp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpyobject\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/GVSU-CIS678/lib/python3.8/site-packages/numba/core/typing/typeof.py\u001B[0m in \u001B[0;36mtypeof\u001B[0;34m(val, purpose)\u001B[0m\n\u001B[1;32m     27\u001B[0m     \u001B[0;31m# Note the behaviour for Purpose.argument must match _typeof.c.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m     \u001B[0mc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_TypeofContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpurpose\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 29\u001B[0;31m     \u001B[0mty\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtypeof_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     30\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mty\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m         msg = _termcolor.errmsg(\n",
      "\u001B[0;32m~/opt/anaconda3/envs/GVSU-CIS678/lib/python3.8/functools.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    873\u001B[0m                             '1 positional argument')\n\u001B[1;32m    874\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 875\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mdispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    876\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    877\u001B[0m     \u001B[0mfuncname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'__name__'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'singledispatch function'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/GVSU-CIS678/lib/python3.8/site-packages/numba/core/typing/typeof.py\u001B[0m in \u001B[0;36m_typeof_set\u001B[0;34m(val, c)\u001B[0m\n\u001B[1;32m    177\u001B[0m     \u001B[0mitem\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    178\u001B[0m     \u001B[0mty\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtypeof_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 179\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSet\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mty\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreflected\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    180\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    181\u001B[0m \u001B[0;34m@\u001B[0m\u001B[0mtypeof_impl\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mregister\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mslice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/GVSU-CIS678/lib/python3.8/site-packages/numba/core/types/abstract.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0mthe\u001B[0m \u001B[0mnew\u001B[0m \u001B[0minstance\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mreturned\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m         \"\"\"\n\u001B[0;32m---> 66\u001B[0;31m         \u001B[0minst\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcls\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     67\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_intern\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minst\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     68\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/GVSU-CIS678/lib/python3.8/site-packages/numba/core/types/containers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, dtype, reflected)\u001B[0m\n\u001B[1;32m    546\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    547\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreflected\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 548\u001B[0;31m         \u001B[0;32massert\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mHashable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mUndefined\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    549\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    550\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreflected\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mreflected\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# get predictions\n",
    "def a():\n",
    "    predictions = predict(test_df, vocab_dict, vocabulary, topic_dict, topic_list)\n",
    "%timeit a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result_df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.8166843783209352"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get overall accuracy\n",
    "accuracy = np.sum(pd.Series(predictions) == result_df[0])/len(result_df)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "we get 81% overall accuracy using our model on the cleaned data. This is not much different from that of a vanilla sklearn MultinomialNB classifier with little additional processing (79.8% accuracy, as shows below)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "A confusion matrix is a tabulation of prediction vs. actual results, telling us the number of instances our model correctly/incorrectly identifies. We create a confusion matrix using pd.crosstab() and calculate precision and recall using the confusion matrix. Precision tells us the percentage of correct predictions for a class out of all predictions. Recall tells us the percentage correct predictions for a class out of all actual instances of a class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_precision(confusion_matrix, topic):\n",
    "    # the number of correct results divided by the number of all results\n",
    "    return confusion_matrix[topic][topic]/confusion_matrix[topic][len(confusion_matrix) - 1]\n",
    "\n",
    "def calc_recall(confusion_matrix, topic):\n",
    "    # the number of correct results divided by the number of results that should have been returned\n",
    "    return confusion_matrix[topic][topic]/confusion_matrix.loc[topic][len(confusion_matrix) - 1]\n",
    "\n",
    "def get_precision_recall(df, pred, topic_list):\n",
    "    # use crosstab to get confusion matrix\n",
    "    confusion_matrix = pd.crosstab(df[0], pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "    # calculate precision and recall\n",
    "    precision = [calc_precision(confusion_matrix, topic) for topic in topic_list]\n",
    "    recall = [calc_recall(confusion_matrix, topic) for topic in topic_list]\n",
    "\n",
    "    # save the calculation results in a dataframe\n",
    "    pr_df = pd.DataFrame(zip(topic_list, precision, recall), columns=['topic', 'precision', 'recall'])\n",
    "    return pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "              topic  precision    recall\n0       motorcycles   0.953728  0.932161\n1          medicine   0.911765  0.861111\n2   mideastpolitics   0.916216  0.901596\n3          politics   0.681648  0.587097\n4           forsale   0.921824  0.725641\n5          xwindows   0.807692  0.803571\n6           atheism   0.778878  0.739812\n7             autos   0.875895  0.929114\n8      christianity   0.737864  0.954774\n9             space   0.847981  0.906091\n10         baseball   0.963255  0.924433\n11             guns   0.681363  0.934066\n12         religion   0.829268  0.406375\n13           hockey   0.941748  0.972431\n14      electronics   0.823529  0.676845\n15       cryptology   0.792373  0.944444\n16               pc   0.645652  0.757653\n17         graphics   0.724880  0.778920\n18        mswindows   0.783282  0.642132\n19              mac   0.792818  0.745455",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>motorcycles</td>\n      <td>0.953728</td>\n      <td>0.932161</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>medicine</td>\n      <td>0.911765</td>\n      <td>0.861111</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mideastpolitics</td>\n      <td>0.916216</td>\n      <td>0.901596</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>politics</td>\n      <td>0.681648</td>\n      <td>0.587097</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>forsale</td>\n      <td>0.921824</td>\n      <td>0.725641</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>xwindows</td>\n      <td>0.807692</td>\n      <td>0.803571</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>atheism</td>\n      <td>0.778878</td>\n      <td>0.739812</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>autos</td>\n      <td>0.875895</td>\n      <td>0.929114</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>christianity</td>\n      <td>0.737864</td>\n      <td>0.954774</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>space</td>\n      <td>0.847981</td>\n      <td>0.906091</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>baseball</td>\n      <td>0.963255</td>\n      <td>0.924433</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>guns</td>\n      <td>0.681363</td>\n      <td>0.934066</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>religion</td>\n      <td>0.829268</td>\n      <td>0.406375</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>hockey</td>\n      <td>0.941748</td>\n      <td>0.972431</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>electronics</td>\n      <td>0.823529</td>\n      <td>0.676845</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>cryptology</td>\n      <td>0.792373</td>\n      <td>0.944444</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>pc</td>\n      <td>0.645652</td>\n      <td>0.757653</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>graphics</td>\n      <td>0.724880</td>\n      <td>0.778920</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>mswindows</td>\n      <td>0.783282</td>\n      <td>0.642132</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>mac</td>\n      <td>0.792818</td>\n      <td>0.745455</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_precision_recall(result_df,pd.Series(predictions),topic_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# sklearn.MultinomialNB\n",
    "\n",
    "Here, we use MultinomialNB classifier from sklearn as a benchmark to compare with our naive bayes model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7983528161530287\n"
     ]
    }
   ],
   "source": [
    "train_data = train_file_data.iloc[:,0].str.split(n=1, expand=True)\n",
    "test_data = test_file_data.iloc[:,0].str.split(n=1, expand=True)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "X_train = count_vect.fit_transform(train_data[1])\n",
    "\n",
    "y_train = np.array(train_data[0])\n",
    "X_test = count_vect.transform(test_data[1])\n",
    "y_test = np.array(test_data[0])\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#conf_mat = confusion_matrix(y_test, y_pred)\n",
    "#conf_mat\n",
    "\n",
    "#from sklearn.metrics import precision_recall_fscore_support\n",
    "#precision_recall_fscore_support(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Discussion\n",
    "\n",
    "Using our model and minimally processed data, we achieved the baseline accuracy of over 79%. Stemming actually decreased overall accuracy, so did removing words consisting of less than 3 letters. However, the difference there was small.\n",
    "\n",
    "There are groups of topics that are closely related. For example, take a look at the top 10 words for atheism, christianity, and religion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "    atheism christianity   religion\n0       god          god        god\n1    people       people     people\n2    writes        jesus      jesus\n3   article        think     writes\n4     think         know    article\n5  atheists       church  christian\n6   atheism      believe       know\n7      know   christians      think\n8   believe       writes      bible\n9  religion    christian       good",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>atheism</th>\n      <th>christianity</th>\n      <th>religion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>god</td>\n      <td>god</td>\n      <td>god</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>people</td>\n      <td>people</td>\n      <td>people</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>writes</td>\n      <td>jesus</td>\n      <td>jesus</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>article</td>\n      <td>think</td>\n      <td>writes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>think</td>\n      <td>know</td>\n      <td>article</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>atheists</td>\n      <td>church</td>\n      <td>christian</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>atheism</td>\n      <td>believe</td>\n      <td>know</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>know</td>\n      <td>christians</td>\n      <td>think</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>believe</td>\n      <td>writes</td>\n      <td>bible</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>religion</td>\n      <td>christian</td>\n      <td>good</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atheism_top_10_counter = Counter(df[1][0]).most_common(10)\n",
    "atheism_top_10 = [k for k,v in atheism_top_10_counter]\n",
    "\n",
    "christianity_top_10_counter = Counter(df[1][3]).most_common(10)\n",
    "christianity_top_10 = [k for k,v in christianity_top_10_counter]\n",
    "\n",
    "religion_top_10_counter = Counter(df[1][17]).most_common(10)\n",
    "religion_top_10 = [k for k,v in religion_top_10_counter]\n",
    "\n",
    "pd.DataFrame({'atheism': atheism_top_10, 'christianity': christianity_top_10, 'religion': religion_top_10})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The similarity among the three may account for the low recall we find in religion (0.406375). We also find closeness of this kind in other groups, for instance, politics and mideastpolitics, xwindows and mswindows.\n",
    "\n",
    "If the classification task is not restricted to the exact 20 topics, we may collapse similar topics into a single topic, and the model performance may improve, since we would have eliminated many correlations.\n",
    "\n",
    "The model has not been tested on a different dataset, although the most relevant functions are written with modularity in mind.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Chenfeng (Aaron) Hao"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}