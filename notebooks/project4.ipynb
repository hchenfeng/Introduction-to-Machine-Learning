{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fishing = pd.read_csv(\"../data/fishing(1).data\", header=None, names=('Wind', 'Air', 'Water', 'Sky', 'Fishing'))\n",
    "fishing_training = fishing.iloc[:14,:]\n",
    "fishing_testing = fishing.iloc[15:,:]\n",
    "digits_training = pd.read_csv(\"../data/digits-train.data\", header=None)\n",
    "digits_testing = pd.read_csv(\"../data/digits-test.data\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "One-hot encoding vs dummy encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dummy_fishing_train =  pd.get_dummies(fishing_training, drop_first=True)\n",
    "dummy_fishing_test =  pd.get_dummies(fishing_testing, drop_first=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_targets = digits_training.iloc[:,-1]\n",
    "train_targets_one_hot = pd.get_dummies(train_targets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "\n",
    "@njit(parallel=True)\n",
    "def min_max_normalize(narr):\n",
    "    new_narr = np.full((narr.shape[1], narr.shape[0]), 0.0)\n",
    "\n",
    "    narr = narr.T\n",
    "\n",
    "    for i in prange(narr.shape[0]):\n",
    "        min_val = np.min(narr[i])\n",
    "        max_val = np.max(narr[i])\n",
    "        diff = max_val - min_val\n",
    "        for j in prange(narr.shape[1]):\n",
    "            if diff == 0:\n",
    "                new_narr[i,j] = 0\n",
    "            else:\n",
    "                new_narr[i,j] = (narr[i,j] - min_val)/diff\n",
    "\n",
    "    return new_narr.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# def min_max_normalize(narr):\n",
    "#     arr_length = len(narr)\n",
    "#     new_narr = np.empty((0,arr_length))\n",
    "#\n",
    "#     for col in narr.T:\n",
    "#         min_val = np.min(col)\n",
    "#         max_val = np.max(col)\n",
    "#         diff = max_val - min_val\n",
    "#         if diff == 0:\n",
    "#             new_narr = np.append(new_narr, [np.zeros((arr_length))], axis=0)\n",
    "#         else:\n",
    "#             min_max_n_vals = np.divide(np.subtract(col, min_val), diff)\n",
    "#             new_narr = np.append(new_narr, [min_max_n_vals], axis=0)\n",
    "#\n",
    "#     return new_narr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_small_rand(length):\n",
    "    return np.random.uniform(-0.001, 0.001, size=(length,))\n",
    "\n",
    "# activation functions\n",
    "\n",
    "@njit\n",
    "def get_sum_of_prod(vec, weights):\n",
    "    vec = np.ascontiguousarray(vec)\n",
    "    weights = np.ascontiguousarray(weights)\n",
    "    return np.dot(vec, weights)\n",
    "\n",
    "@njit\n",
    "def activation_binary_sigmoid(sigma):\n",
    "    return 1 / (1 + np.e ** (-sigma))\n",
    "\n",
    "# @njit\n",
    "# def activation_softmax(sigmas):\n",
    "#     return np.exp(sigmas) / np.sum(np.exp(sigmas))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "@njit\n",
    "def feed_forward(vec, weights):\n",
    "    sop = get_sum_of_prod(vec, weights)\n",
    "    out = activation_binary_sigmoid(sop)\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_rmse(t_vec, y_vec):\n",
    "    return np.sqrt(np.sum(np.square(np.subtract(t_vec, y_vec))))/len(t_vec)\n",
    "\n",
    "@njit\n",
    "def get_sigmoid_loss(t_vec, y_vec):\n",
    "    d = np.multiply(y_vec, 1 - y_vec)\n",
    "    e = t_vec - y_vec\n",
    "    return np.multiply(d, e)\n",
    "\n",
    "@njit\n",
    "def get_hidden_loss(h, w_vec, e_vec):\n",
    "    h_d = np.multiply(h, 1-h)\n",
    "    w_e_dot = np.dot(w_vec, e_vec)\n",
    "    return np.multiply(h_d, w_e_dot)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "@njit\n",
    "def update_weights(error, weights, outs, learning_rate):\n",
    "    temp = learning_rate * error\n",
    "    adjustments = np.outer(outs, temp)\n",
    "    return np.add(weights, adjustments)\n",
    "\n",
    "    # for i in prange(error.shape[0]):\n",
    "    #     temp = learning_rate * error[i]\n",
    "    #     weights_adjustments[i] = np.multiply(outs, temp)\n",
    "    #\n",
    "    # return np.add(weights, weights_adjustments.T)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_input = digits_training.iloc[:,:-1].to_numpy(dtype=float)\n",
    "train_output = pd.get_dummies(digits_training.iloc[:,-1]).to_numpy(dtype=float)\n",
    "train_input_normalized = min_max_normalize(train_input)\n",
    "\n",
    "test_input = digits_testing.iloc[:,:-1].to_numpy(dtype=float)\n",
    "test_output = pd.get_dummies(digits_testing.iloc[:,-1]).to_numpy(dtype=float)\n",
    "test_input_normalized = min_max_normalize(test_input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# arr_t = train_input_normalized.T\n",
    "#\n",
    "# arr_t1 = np.array([1.0]*3823)\n",
    "#\n",
    "# new_in = np.concatenate(([arr_t1], arr_t)).T\n",
    "# input_weights = np.reshape(get_small_rand(65 * 50), (65, 50))\n",
    "#\n",
    "# hidden_outs = feed_forward(new_in[0], input_weights)\n",
    "# new_hidden_outs = np.concatenate(([1.0], hidden_outs))\n",
    "#\n",
    "# hidden_weights = np.reshape(get_small_rand(51 * 10), (51, 10))\n",
    "#\n",
    "# first = feed_forward(new_hidden_outs, hidden_weights)\n",
    "#\n",
    "# s_loss = get_sigmoid_loss(train_output[0], first)\n",
    "#\n",
    "# test_arr = np.full((10, 51), 0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "@njit\n",
    "def train_neural_net(X, Y, epoch=1, learning_rate=0.5):\n",
    "\n",
    "    input_n_row = X.shape[0]\n",
    "    # create array of 1s\n",
    "    temp_arr = np.array(([1.0] * input_n_row))\n",
    "    # prepend 1 to each instance\n",
    "    new_input = np.concatenate((temp_arr.reshape(1,input_n_row), X.T)).T\n",
    "\n",
    "    # use random number between -.001 and .001 as input weights\n",
    "    # 65 because 64 inputs and 1 bias\n",
    "    # 50 because 50 hidden nodes\n",
    "    input_weights = np.reshape(get_small_rand(65 * 50), (65, 50))\n",
    "    # input_weights = np.array([1,1,0.5],[1,-1,2])\n",
    "\n",
    "    # similarly for hidden layer weights\n",
    "    # 51 because 50 nodes (2/3 of the sum of input and output nodes) and 1 more for bias\n",
    "    # 10 because 10 output nodes\n",
    "    hidden_weights = np.reshape(get_small_rand(51 * 10), (51, 10))\n",
    "    # hidden_weights = np.array([1,1.5,-1])\n",
    "\n",
    "    rmse = np.zeros((epoch,))\n",
    "\n",
    "    for i in range(epoch):\n",
    "        target = np.array([0.])\n",
    "        y_bar = np.array([0.])\n",
    "        for row in range(X.shape[0]):\n",
    "\n",
    "            # outputs at hidden nodes\n",
    "            hidden_outs = feed_forward(new_input[row], input_weights)\n",
    "            # prepend 1 as bias\n",
    "            new_hidden_outs = np.concatenate((np.array([1.0]), hidden_outs))\n",
    "            # current output\n",
    "            y_bar = feed_forward(new_hidden_outs, hidden_weights)\n",
    "            # current target\n",
    "            target = Y[row]\n",
    "            # backpropagated output error\n",
    "            output_error = get_sigmoid_loss(target, y_bar)\n",
    "            # backpropagated hidden error\n",
    "            hidden_error = get_hidden_loss(hidden_outs, hidden_weights[1:], output_error)\n",
    "\n",
    "            new_hidden_weights = update_weights(output_error,hidden_weights, new_hidden_outs, learning_rate)\n",
    "            hidden_weights = new_hidden_weights\n",
    "\n",
    "            new_input_weights = update_weights(hidden_error,input_weights, new_input[row], learning_rate)\n",
    "            input_weights = new_input_weights\n",
    "        # current rmse\n",
    "        current_rmse = get_rmse(target, y_bar)\n",
    "        rmse[i] = current_rmse\n",
    "\n",
    "    return input_weights, hidden_weights, rmse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "test = train_neural_net(train_input_normalized, train_output, epoch=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(test[2]).plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# @njit\n",
    "def neural_net_predict(input_ws, hidden_ws, X, Y):\n",
    "    input_n_row = X.shape[0]\n",
    "    temp_arr = np.array(([1.0] * input_n_row))\n",
    "    new_X = np.concatenate((temp_arr.reshape(1,input_n_row), X.T)).T\n",
    "    hidden_outs = feed_forward(new_X, input_ws)\n",
    "    new_hidden_outs = np.concatenate((np.array([1.0]*input_n_row).reshape(1,input_n_row), hidden_outs.T)).T\n",
    "    outs = feed_forward(new_hidden_outs, hidden_ws)\n",
    "    preds = outs.argmax(1)\n",
    "    return np.sum(preds == Y) / input_n_row"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Although optimization is not part of the goal for this assignment, experiment was attempted using the @njit decorator in the Numba package, which translates decorated python code into fast machine code using LLVM.\n",
    "\n",
    "Results show significant improvement when compared with the version not decorated with @njit. Still, the usual caution applies: vector operations are preferred over loops. Replacing a loop with np.out() in the update_weights() function significantly improved the runtime of the current model.\n",
    "\n",
    "In the current implementation of training, 20 epochs takes about a bit over 1s to run.\n",
    "\n",
    "It was mentioned that implementation of neural network may be slow in R."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.03 s ± 525 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# %timeit train_neural_net(train_input_normalized, train_output, epoch=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "weights = train_neural_net(train_input_normalized, train_output, epoch=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9963379544860057"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net_predict(weights[0], weights[1], train_input_normalized, digits_training.iloc[:,-1].to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9666110183639399"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net_predict(weights[0], weights[1], test_input_normalized, digits_testing.iloc[:,-1].to_numpy())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-88dd0e96",
   "language": "python",
   "display_name": "PyCharm (GVSU-CIS678)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}