{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fishing = pd.read_csv(\"../data/fishing(1).data\", header=None, names=('Wind', 'Air', 'Water', 'Sky', 'Fishing'))\n",
    "fishing_training = fishing.iloc[:14,:]\n",
    "fishing_testing = fishing.iloc[15:,:]\n",
    "digits_training = pd.read_csv(\"../data/digits-train.data\", header=None)\n",
    "digits_testing = pd.read_csv(\"../data/digits-test.data\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "One-hot encoding vs dummy encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dummy_fishing_train =  pd.get_dummies(fishing_training, drop_first=True)\n",
    "dummy_fishing_test =  pd.get_dummies(fishing_testing, drop_first=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_targets = digits_training.iloc[:,-1]\n",
    "train_targets_one_hot = pd.get_dummies(train_targets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "\n",
    "@njit(parallel=True)\n",
    "def min_max_normalize(narr):\n",
    "    new_narr = np.full((narr.shape[1], narr.shape[0]), 0.0)\n",
    "\n",
    "    narr = narr.T\n",
    "\n",
    "    for i in prange(narr.shape[0]):\n",
    "        min_val = np.min(narr[i])\n",
    "        max_val = np.max(narr[i])\n",
    "        diff = max_val - min_val\n",
    "        for j in prange(narr.shape[1]):\n",
    "            if diff == 0:\n",
    "                new_narr[i,j] = 0\n",
    "            else:\n",
    "                new_narr[i,j] = (narr[i,j] - min_val)/diff\n",
    "\n",
    "    return new_narr.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# def min_max_normalize(narr):\n",
    "#     arr_length = len(narr)\n",
    "#     new_narr = np.empty((0,arr_length))\n",
    "#\n",
    "#     for col in narr.T:\n",
    "#         min_val = np.min(col)\n",
    "#         max_val = np.max(col)\n",
    "#         diff = max_val - min_val\n",
    "#         if diff == 0:\n",
    "#             new_narr = np.append(new_narr, [np.zeros((arr_length))], axis=0)\n",
    "#         else:\n",
    "#             min_max_n_vals = np.divide(np.subtract(col, min_val), diff)\n",
    "#             new_narr = np.append(new_narr, [min_max_n_vals], axis=0)\n",
    "#\n",
    "#     return new_narr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_small_rand(length):\n",
    "    return np.random.uniform(-0.001, 0.001, size=(length,))\n",
    "\n",
    "# activation functions\n",
    "\n",
    "@njit\n",
    "def get_sum_of_prod(vec, weights):\n",
    "    vec = np.ascontiguousarray(vec)\n",
    "    weights = np.ascontiguousarray(weights)\n",
    "    return np.dot(vec, weights)\n",
    "\n",
    "@njit\n",
    "def activation_binary_sigmoid(sigma):\n",
    "    return 1 / (1 + np.e ** (-sigma))\n",
    "\n",
    "# @njit\n",
    "# def activation_softmax(sigmas):\n",
    "#     return np.exp(sigmas) / np.sum(np.exp(sigmas))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "@njit\n",
    "def feed_forward(vec, weights):\n",
    "    sop = get_sum_of_prod(vec, weights)\n",
    "    out = activation_binary_sigmoid(sop)\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_rmse(t_vec, y_vec):\n",
    "    return np.sqrt(np.sum(np.square(np.subtract(t_vec, y_vec))))/len(t_vec)\n",
    "\n",
    "@njit\n",
    "def get_sigmoid_loss(t_vec, y_vec):\n",
    "    d = np.multiply(y_vec, 1 - y_vec)\n",
    "    e = t_vec - y_vec\n",
    "    return np.multiply(d, e)\n",
    "\n",
    "@njit\n",
    "def get_hidden_loss(h, w_vec, e_vec):\n",
    "    h_d = np.multiply(h, 1-h)\n",
    "    return np.multiply(h_d, np.dot(w_vec, e_vec))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def update_weights(arr_init, error, weights, outs, learning_rate):\n",
    "    weights_adjustments = arr_init\n",
    "\n",
    "    for i in prange(error.shape[0]):\n",
    "        temp = learning_rate * error[i]\n",
    "        weights_adjustments[i] = np.multiply(outs, temp)\n",
    "\n",
    "    return np.add(weights, weights_adjustments.T)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "train_input = digits_training.iloc[:,:-1].to_numpy(dtype=float)\n",
    "train_output = pd.get_dummies(digits_training.iloc[:,-1]).to_numpy(dtype=float)\n",
    "train_input_normalized = min_max_normalize(train_input)\n",
    "\n",
    "test_input = digits_testing.iloc[:,:-1].to_numpy(dtype=float)\n",
    "test_output = pd.get_dummies(digits_testing.iloc[:,-1]).to_numpy(dtype=float)\n",
    "test_input_normalized = min_max_normalize(test_input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# arr_t = train_input_normalized.T\n",
    "#\n",
    "# arr_t1 = np.array([1.0]*3823)\n",
    "#\n",
    "# new_in = np.concatenate(([arr_t1], arr_t)).T\n",
    "# input_weights = np.reshape(get_small_rand(65 * 50), (65, 50))\n",
    "#\n",
    "# hidden_outs = feed_forward(new_in[0], input_weights)\n",
    "# new_hidden_outs = np.concatenate(([1.0], hidden_outs))\n",
    "#\n",
    "# hidden_weights = np.reshape(get_small_rand(51 * 10), (51, 10))\n",
    "#\n",
    "# first = feed_forward(new_hidden_outs, hidden_weights)\n",
    "#\n",
    "# s_loss = get_sigmoid_loss(train_output[0], first)\n",
    "#\n",
    "# test_arr = np.full((10, 51), 0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "@njit\n",
    "def train_neural_net(X, Y, epoch=1, learning_rate=0.5):\n",
    "\n",
    "    input_n_row = X.shape[0]\n",
    "    # create array of 1s\n",
    "    temp_arr = np.array(([1.0] * input_n_row))\n",
    "    # prepend 1 to each instance\n",
    "    new_input = np.concatenate((temp_arr.reshape(1,input_n_row), X.T)).T\n",
    "\n",
    "    # use random number between -.001 and .001 as input weights\n",
    "    # 65 because 64 inputs and 1 bias\n",
    "    # 50 because 50 hidden nodes\n",
    "    input_weights = np.reshape(get_small_rand(65 * 50), (65, 50))\n",
    "\n",
    "    # similarly for hidden layer weights\n",
    "    # 51 because 50 nodes (2/3 of the sum of input and output nodes) and 1 more for bias\n",
    "    # 10 because 10 output nodes\n",
    "    hidden_weights = np.reshape(get_small_rand(51 * 10), (51, 10))\n",
    "\n",
    "    rmse = np.array([0.])\n",
    "\n",
    "    for _ in prange(epoch):\n",
    "\n",
    "        for row in prange(X.shape[0]):\n",
    "\n",
    "            # outputs at hidden nodes\n",
    "            hidden_outs = feed_forward(new_input[row], input_weights)\n",
    "            # prepend 1 as bias\n",
    "            new_hidden_outs = np.concatenate((np.array([1.0]), hidden_outs))\n",
    "            # current output\n",
    "            y_bar = feed_forward(new_hidden_outs, hidden_weights)\n",
    "            # current target\n",
    "            target = Y[row]\n",
    "            # current rmse\n",
    "            current_rmse = get_rmse(target, y_bar)\n",
    "\n",
    "            rmse = np.append(rmse, current_rmse)\n",
    "\n",
    "            # backpropagated output error\n",
    "            output_error = get_sigmoid_loss(target, y_bar)\n",
    "            # backpropagated hidden error\n",
    "            hidden_error = get_hidden_loss(hidden_outs, hidden_weights[1:], output_error)\n",
    "\n",
    "            # hidden_weights_adjustments = np.full((10, 51), 0.0)\n",
    "            #\n",
    "            # for i in range(output_error.shape[0]):\n",
    "            #     hidden_weights_adjustments[i] = np.multiply(new_hidden_outs, output_error[i])\n",
    "            #\n",
    "            # new_hidden_weights = np.add(hidden_weights, hidden_weights_adjustments.T)\n",
    "            new_hidden_weights = update_weights(np.full((10, 51), 0.0), output_error,hidden_weights, new_hidden_outs, learning_rate)\n",
    "            hidden_weights = new_hidden_weights\n",
    "\n",
    "            # input_weights_adjustments = np.full((50, 65), 0.0)\n",
    "            #\n",
    "            # for j in range(hidden_error.shape[0]):\n",
    "            #     input_weights_adjustments[j] = np.multiply(new_input[0], hidden_error[j])\n",
    "            #\n",
    "            # new_input_weights = np.add(input_weights, input_weights_adjustments.T)\n",
    "            new_input_weights = update_weights(np.full((50, 65), 0.0), hidden_error,input_weights, new_input[row], learning_rate)\n",
    "            input_weights = new_input_weights\n",
    "\n",
    "    # final_hidden_outs = feed_forward(new_input[100], input_weights)\n",
    "    # final_hidden_outs = np.concatenate((np.array([1.0]), final_hidden_outs))\n",
    "    # final_outputs = feed_forward(final_hidden_outs, hidden_weights)\n",
    "\n",
    "    return input_weights, hidden_weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# @njit\n",
    "def neural_net_predict(input_ws, hidden_ws, X, Y):\n",
    "    input_n_row = X.shape[0]\n",
    "    temp_arr = np.array(([1.0] * input_n_row))\n",
    "    new_X = np.concatenate((temp_arr.reshape(1,input_n_row), X.T)).T\n",
    "    hidden_outs = feed_forward(new_X, input_ws)\n",
    "    new_hidden_outs = np.concatenate((np.array([1.0]*input_n_row).reshape(1,input_n_row), hidden_outs.T)).T\n",
    "    outs = feed_forward(new_hidden_outs, hidden_ws)\n",
    "    preds = outs.argmax(1)\n",
    "    return np.sum(preds == Y) / input_n_row"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [],
   "source": [
    "weights = train_neural_net(train_input_normalized, train_output, epoch=60)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9968611038451478"
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net_predict(weights[0], weights[1], train_input_normalized, digits_training.iloc[:,-1].to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9649415692821369"
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net_predict(weights[0], weights[1], test_input_normalized, digits_testing.iloc[:,-1].to_numpy())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-88dd0e96",
   "language": "python",
   "display_name": "PyCharm (GVSU-CIS678)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}