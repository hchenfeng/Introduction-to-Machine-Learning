{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this exercise, we are implementing a basic form of the ID3 algorithm in Python.\n",
    "\n",
    "# Data\n",
    "\n",
    "The provided data are all comma-separated, with metadata at the beginning. All predictor variables appear before the class variable. We make the same assumption about data in our implementation of ID3.\n",
    "\n",
    "It's easy to hand type the variable names for each dataset. However, as they are so well-structured, we programmatically extract the variable names from the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cad_file = \"../data/CAD.data\"\n",
    "fishing_file = \"../data/fishing.data\"\n",
    "contact_lenses_file = \"../data/contact-lenses.data\"\n",
    "caesarian_file = \"../data/caesarian.data\"\n",
    "\n",
    "cad = pd.read_csv(cad_file, header=None, comment='#')\n",
    "fishing = pd.read_csv(fishing_file, header=None, comment='#')\n",
    "contact_lenses = pd.read_csv(contact_lenses_file, header=None, comment='#')\n",
    "caesarian = pd.read_csv(caesarian_file, header=None, comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# programmatically extract the variable names from the metadata\n",
    "import string\n",
    "\n",
    "def get_colnames(file):\n",
    "    with open(file) as f:\n",
    "        lines = []\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                lines.append(line.rstrip().strip('#'))\n",
    "        names = [line.translate(str.maketrans('', '', string.punctuation)).split()[0] for line in lines]\n",
    "        return names[2:-2] + [names[-1]]\n",
    "\n",
    "cad_colnames = get_colnames(cad_file)\n",
    "fishing_colnames = get_colnames(fishing_file)\n",
    "contact_lenses_colnames = get_colnames(contact_lenses_file)\n",
    "caesarian_colnames = get_colnames(caesarian_file)\n",
    "\n",
    "cad.columns = cad_colnames\n",
    "fishing.columns = fishing_colnames\n",
    "contact_lenses.columns = contact_lenses_colnames\n",
    "caesarian.columns = caesarian_colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# practice using pickle, although there is no need for it here\n",
    "\n",
    "import pickle\n",
    "\n",
    "infile = \"../data/decision_tree_data.pickle\"\n",
    "\n",
    "with open(infile,'wb') as f:\n",
    "    pickle.dump(cad, f)\n",
    "    pickle.dump(fishing, f)\n",
    "    pickle.dump(contact_lenses, f)\n",
    "    pickle.dump(caesarian, f)\n",
    "\n",
    "with open(infile, 'rb') as f:\n",
    "    cad1 = pickle.load(f)\n",
    "    fishing1 = pickle.load(f)\n",
    "    contact_lenses1 = pickle.load(f)\n",
    "    caesarian1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ID3 Implementation\n",
    "\n",
    "To get the entropy of a set, we implement the following:\n",
    "\n",
    "$$ Entropy(S) = -\\sum \\limits_{i=1}^k p_i log_2p_i $$\n",
    "\n",
    "A problem that arises is when a class value does not appear in a set, where we have a probability of 0. $$ log_20 = \\infty $$ However, to make it easy for our algorithm, we assume $$ log_20 = 0 $$\n",
    "\n",
    "To get the information gain of a value a, we implement the following:\n",
    "\n",
    "$$ Gain(S,a) = Entropy(S) - \\sum \\limits_{v=value(a)} {\\frac{\\lvert S_v \\rvert}{\\lvert S \\rvert}} Entropy(S_v) $$\n",
    "\n",
    "We make a number of assumptions specific to the four datasets provided for this exercise.\n",
    "\n",
    "- Class variable always appears in the last column.\n",
    "- Numerical variable is of type 'int64'.\n",
    "\n",
    "Two main data structures used are dictionary and tree.\n",
    "\n",
    "We use dictionaries whenever the relevant data cannot be easily indexed by integers. A dictionary is efficient for retrieving values, with O(1). A dictionary is not ordered by default. We make use of OrderedDict to simplify the calculation of information gain.\n",
    "\n",
    "The Tree() object in Treelib makes a number of things easier. We could have used Node or create a class on top of Node with additional features. However, among other things, Treelib provides a basic ascii graph, indexes nodes with unique ids, and can export .dot files for graphviz. The downside is that we are unable to directly distinguish features from feature values in the resulted trees. In a Treelib defined tree, every endpoint is a node distinguished by unique ids and other attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_entropy(arr):\n",
    "    # set count to 0 if class value does not exist\n",
    "    arr = [0 if v is None else v for v in arr]\n",
    "    # get cardinality\n",
    "    probs = np.divide(arr, np.sum(arr))\n",
    "    # get log2 of probabilities, assign 0 to log2(0)\n",
    "    log2p = [0 if prob == 0 else np.log2(prob) for prob in probs]\n",
    "    return -np.sum(np.multiply(probs, log2p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import operator\n",
    "import copy\n",
    "\n",
    "# helper function extracted from get_attribute_w_max_information_gain()\n",
    "def calculate_information_gain(cardinality_dict, entropy_dict, class_entropy):\n",
    "    # sort cardinalities by keys\n",
    "    cardinalities = list(dict(OrderedDict(sorted(cardinality_dict.items()))).values())\n",
    "    # sort entropies by keys\n",
    "    entropies = list(dict(OrderedDict(sorted(entropy_dict.items()))).values())\n",
    "    # calculate information gain\n",
    "    information_gain = class_entropy - np.sum(np.multiply(cardinalities, entropies))\n",
    "    return information_gain\n",
    "\n",
    "def get_attribute_w_max_information_gain(df):\n",
    "\n",
    "    # get counts for class values\n",
    "    class_value_counts = df.iloc[:,-1:].value_counts().values\n",
    "    # get class entropy\n",
    "    class_entropy = get_entropy(class_value_counts)\n",
    "    # get unique class values\n",
    "    class_values = pd.unique(df.iloc[:,-1])\n",
    "\n",
    "    # initialize empty dictionary of information gain\n",
    "    information_gain_dict = {}\n",
    "\n",
    "    # assumes class variable is in the last column\n",
    "    # get predictor variables/attributes\n",
    "    attributes = [x for x in df.columns[:-1]]\n",
    "\n",
    "    # assume data types limited to 'object' (string) and 'int64'\n",
    "    for attr in attributes:\n",
    "        # when attribute is categorical\n",
    "        if df[attr].dtype == 'object':\n",
    "            # store value counts to a variable\n",
    "            value_count = df[attr].value_counts()\n",
    "            # sum up value counts\n",
    "            value_count_sum = value_count.sum()\n",
    "            # store cardinality to a dictionary\n",
    "            cardinality_dict = (value_count/value_count_sum).to_dict()\n",
    "\n",
    "            # initialize empty list for storing counts\n",
    "            count_arr = []\n",
    "            # initialize empty dictionary for storing entropies\n",
    "            entropy_dict = {}\n",
    "\n",
    "            # get unique values of an attribute\n",
    "            var_values = df[attr].unique()\n",
    "\n",
    "            # get attribute column index\n",
    "            col_ind = df.columns.get_loc(attr)\n",
    "            # get count of class values by attribute values\n",
    "            attr_class_count = df.iloc[:,[col_ind,-1]].value_counts()\n",
    "\n",
    "            # iterate through attribute values to get each of their entropies\n",
    "            for var_value in var_values:\n",
    "                for class_value in class_values:\n",
    "                    count_arr.append(attr_class_count.get((var_value, class_value)))\n",
    "                entropy_dict[var_value] = get_entropy(count_arr)\n",
    "                count_arr = []\n",
    "\n",
    "            # store attribute entropy to a dictionary\n",
    "            information_gain_dict[attr] = calculate_information_gain(cardinality_dict, entropy_dict, class_entropy)\n",
    "\n",
    "        # when attribute is of type 'int64'\n",
    "        elif df[attr].dtype == 'int64':\n",
    "            # get attribute column index\n",
    "            col_ind = df.columns.get_loc(attr)\n",
    "            # get new dataframe with only current attribute and class variable\n",
    "            new_df = df.iloc[:,[col_ind,-1]]\n",
    "\n",
    "            # sort new dataframe by attribute\n",
    "            new_df_sorted = new_df.sort_values(by=[attr]).reset_index(drop=True)\n",
    "            # initialize empty list for split values\n",
    "            split_values = []\n",
    "\n",
    "            # split at the mean value of adjacent attribute values of bordering class values\n",
    "            for j in range(len(new_df_sorted) - 1):\n",
    "                # if class value of an instance is different from that of the next instance\n",
    "                if new_df_sorted.iloc[j, 1] != new_df_sorted.iloc[j + 1, 1]:\n",
    "                    # split value is the mean of the corresponding attribute values\n",
    "                    split_value = (new_df_sorted.iloc[j, 0] + new_df_sorted.iloc[j + 1, 0]) / 2\n",
    "                    split_values.append(split_value)\n",
    "\n",
    "            # initialize empty information gain dictionary for numeric attributes\n",
    "            info_gain_dict_num = {}\n",
    "\n",
    "            # select split value with highest information gain\n",
    "            for value in split_values:\n",
    "                # initialize empty dictionary for entropies of split values\n",
    "                num_entropy_dict = {}\n",
    "\n",
    "                # get a fresh copy of the new dataframe\n",
    "                # shallow copy would keep the label\n",
    "                new_df_sorted2 = copy.deepcopy(new_df_sorted)\n",
    "                # get index of values smaller than split\n",
    "                ind = new_df_sorted2[attr] < float(value)\n",
    "                # get index of values greater than or equal to split\n",
    "                ind1 = new_df_sorted2[attr] >= float(value)\n",
    "\n",
    "                # labels\n",
    "                label1 = '< ' + str(value)\n",
    "                label2 = '>= ' + str(value)\n",
    "\n",
    "                # assign labels\n",
    "                new_df_sorted2.iloc[ind, 0] = label1\n",
    "                new_df_sorted2.iloc[ind1, 0] = label2\n",
    "\n",
    "                # get value counts of labels\n",
    "                attr_class_count = new_df_sorted2.value_counts()\n",
    "\n",
    "                count_arr = []\n",
    "                for label in (label1, label2):\n",
    "                    for class_value in class_values:\n",
    "                        count_arr.append(attr_class_count.get((label, class_value)))\n",
    "                    num_entropy_dict[label] = get_entropy(count_arr)\n",
    "                    count_arr = []\n",
    "\n",
    "                value_count = new_df_sorted2[attr].value_counts()\n",
    "\n",
    "                value_count_sum = value_count.sum()\n",
    "                cardinality_dict = (value_count/value_count_sum).to_dict()\n",
    "                info_gain_dict_num[value] = calculate_information_gain(cardinality_dict, num_entropy_dict, class_entropy)\n",
    "            max_gain_key = max(info_gain_dict_num.items(), key=operator.itemgetter(1))[0]\n",
    "            information_gain_dict[('Age' + '<' + str(max_gain_key))] = np.around(info_gain_dict_num[max_gain_key],decimals=3)\n",
    "\n",
    "    max_key = max(information_gain_dict.items(), key=operator.itemgetter(1))[0]\n",
    "    return [max_key, information_gain_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from treelib import Tree\n",
    "import uuid, re\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "def grow_tree(tree, branch, new_id, parent_id):\n",
    "    if tree.size() == 0:\n",
    "        tree.create_node(branch, new_id)\n",
    "    else:\n",
    "        tree.create_node(branch, new_id, parent=parent_id)\n",
    "        \n",
    "def dynamic_tree(tree, msg='', delay=1):\n",
    "    print(msg)\n",
    "    time.sleep(delay)\n",
    "    clear_output(wait=True)\n",
    "    tree.show()\n",
    "    time.sleep(delay)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "\n",
    "def id3(df, tree, parent = None, parent_majority_class = None):\n",
    "    # cover cases with empty input\n",
    "    if df.size == 0:\n",
    "        return \"Data Frame is empty.\"\n",
    "\n",
    "    # get the number of classes\n",
    "    class_values_length = len(pd.unique(df.iloc[:,-1]))\n",
    "\n",
    "    # use an uuid as a node id\n",
    "    branch_id = uuid.uuid4()\n",
    "\n",
    "    # grow leaf if all instances are of the same class\n",
    "    if class_values_length == 1:\n",
    "        leaf_value = df.iloc[0,-1:].values[0]\n",
    "        grow_tree(tree, leaf_value, branch_id, parent)\n",
    "        # dynamic_tree('All instances are in the same class.')\n",
    "\n",
    "    # grow leaf with majority class label if only one feature variable left\n",
    "    elif len(df.columns) == 1:\n",
    "        if len(set(df.iloc[:,-1:].value_counts())) == 1:\n",
    "            leaf_value = parent_majority_class\n",
    "            grow_tree(tree, leaf_value, branch_id, parent)\n",
    "        else:\n",
    "            leaf_value = df.iloc[:,-1:].value_counts().idxmax()[0]\n",
    "            grow_tree(tree, leaf_value, branch_id, parent)\n",
    "        # dynamic_tree('No more variable. Choose majority class.')\n",
    "    else:\n",
    "        parent_majority_class = df.iloc[:,-1:].value_counts().idxmax()[0]\n",
    "        max_information_gain_result = get_attribute_w_max_information_gain(df)\n",
    "        node_var = max_information_gain_result[0]\n",
    "        msg = max_information_gain_result\n",
    "\n",
    "        var_name = None\n",
    "\n",
    "        if node_var in df.columns.values:\n",
    "            grow_tree(tree, node_var, branch_id, parent)\n",
    "            # dynamic_tree(msg)\n",
    "            is_num_var = False\n",
    "            col_values = list(np.unique(df[node_var].values))\n",
    "        else:\n",
    "            is_num_var = True\n",
    "            node_var_name_split = str.split(node_var, '<')\n",
    "            var_name = node_var_name_split[0]\n",
    "            var_num_value = node_var_name_split[1]\n",
    "            grow_tree(tree, var_name, branch_id, parent)\n",
    "            # dynamic_tree(msg)\n",
    "            split1 = var_name + '<' + var_num_value\n",
    "            split2 = var_name + '>=' + var_num_value\n",
    "            col_values = [split1, split2]\n",
    "\n",
    "        new_parent = branch_id\n",
    "\n",
    "        if is_num_var:\n",
    "            new_branch_id1 = uuid.uuid4()\n",
    "            new_branch_id2 = uuid.uuid4()\n",
    "            tree.create_node(col_values[0], new_branch_id1, parent=new_parent)\n",
    "            # dynamic_tree(msg)\n",
    "            tree.create_node(col_values[1], new_branch_id2, parent=new_parent)\n",
    "            # dynamic_tree(msg)\n",
    "            name_value = re.split('<|>=', col_values[0])\n",
    "            name = name_value[0]\n",
    "            val = name_value[1]\n",
    "            ind1 = df[name] < float(val)\n",
    "            ind2 = df[name] >= float(val)\n",
    "            df1 = df[ind1]\n",
    "            df2 = df[ind2]\n",
    "            if df1.size == 0:\n",
    "                tree.remove_node(new_branch_id1)\n",
    "                dynamic_tree(msg)\n",
    "            else:\n",
    "                new_bid = uuid.uuid4()\n",
    "                if len(np.unique(df1.iloc[:,-1:].values)) == 1:\n",
    "                    leaf_value = df1.iloc[0,-1:].values[0]\n",
    "                    grow_tree(tree, leaf_value, new_bid, new_branch_id1)\n",
    "                    # dynamic_tree(msg)\n",
    "                elif df2.size == 0:\n",
    "                    leaf_value = df1.iloc[:,-1:].mode().values[0][0]\n",
    "                    grow_tree(tree, leaf_value, new_bid, new_branch_id1)\n",
    "                    # dynamic_tree(msg)\n",
    "                else:\n",
    "                    new_df = df1.drop(var_name, axis=1)\n",
    "                    id3(new_df, tree, new_branch_id1, parent_majority_class)\n",
    "\n",
    "            if df2.size == 0:\n",
    "                tree.remove_node(new_branch_id2)\n",
    "                # dynamic_tree(msg)\n",
    "            else:\n",
    "                new_bid = uuid.uuid4()\n",
    "                if len(np.unique(df2.iloc[:,-1:].values)) == 1:\n",
    "                    leaf_value = df2.iloc[0,-1:].values[0]\n",
    "                    grow_tree(tree, leaf_value, new_bid, new_branch_id2)\n",
    "                    # dynamic_tree(msg)\n",
    "                elif df1.size == 0:\n",
    "                    leaf_value = df2.iloc[:,-1:].mode().values[0][0]\n",
    "                    grow_tree(tree, leaf_value, new_bid, new_branch_id2)\n",
    "                    # dynamic_tree(msg)\n",
    "                else:\n",
    "                    new_df = df2.drop(var_name, axis=1)\n",
    "                    id3(new_df, tree, new_branch_id2, parent_majority_class)\n",
    "\n",
    "        else:\n",
    "            for value in col_values:\n",
    "                new_branch_id = uuid.uuid4()\n",
    "                tree.create_node(value, new_branch_id, parent=new_parent)\n",
    "                # dynamic_tree(msg)\n",
    "                ind = df[node_var] == value\n",
    "                df_v = df[ind].drop(node_var, axis=1)\n",
    "                id3(df_v, tree, new_branch_id, parent_majority_class)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardiac\n",
      "├── abnormal\n",
      "│   └── BP\n",
      "│       ├── high\n",
      "│       │   └── Delivery\n",
      "│       │       ├── late\n",
      "│       │       │   └── Age\n",
      "│       │       │       ├── Age<34.5\n",
      "│       │       │       │   └── no\n",
      "│       │       │       └── Age>=34.5\n",
      "│       │       │           └── yes\n",
      "│       │       ├── normal\n",
      "│       │       │   └── yes\n",
      "│       │       └── premature\n",
      "│       │           └── yes\n",
      "│       ├── low\n",
      "│       │   └── yes\n",
      "│       └── normal\n",
      "│           └── Age\n",
      "│               ├── Age<26.5\n",
      "│               │   └── no\n",
      "│               └── Age>=26.5\n",
      "│                   └── Delivery\n",
      "│                       ├── late\n",
      "│                       │   └── no\n",
      "│                       └── normal\n",
      "│                           └── yes\n",
      "└── normal\n",
      "    └── Age\n",
      "        ├── Age<22.0\n",
      "        │   └── BP\n",
      "        │       ├── high\n",
      "        │       │   └── yes\n",
      "        │       ├── low\n",
      "        │       │   └── yes\n",
      "        │       └── normal\n",
      "        │           └── Delivery\n",
      "        │               └── normal\n",
      "        │                   └── yes\n",
      "        └── Age>=22.0\n",
      "            └── Delivery\n",
      "                ├── late\n",
      "                │   └── BP\n",
      "                │       ├── high\n",
      "                │       │   └── no\n",
      "                │       ├── low\n",
      "                │       │   └── no\n",
      "                │       └── normal\n",
      "                │           └── no\n",
      "                ├── normal\n",
      "                │   └── BP\n",
      "                │       ├── high\n",
      "                │       │   └── no\n",
      "                │       ├── low\n",
      "                │       │   └── yes\n",
      "                │       └── normal\n",
      "                │           └── no\n",
      "                └── premature\n",
      "                    └── BP\n",
      "                        ├── high\n",
      "                        │   └── yes\n",
      "                        ├── low\n",
      "                        │   └── no\n",
      "                        └── normal\n",
      "                            └── no\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id3(caesarian1, Tree()).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems prepruning by way of stopping when there is less that 5% of samples left is not reducing the complexity of the trees.\n",
    "\n",
    "Postpruning can include many methods. Here we experiment with collapsing paring branches where the leaves are of the same class. In other words, we are taking the bottom-up approach.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def prune_tree(tree):\n",
    "    # assume tree depth greater than 2 for simplicity\n",
    "    if tree.depth() < 3:\n",
    "        return\n",
    "\n",
    "    leaves = tree.leaves()\n",
    "\n",
    "    parent_ids = []\n",
    "\n",
    "    for i in range(len(leaves)):\n",
    "        parent_ids.append(tree.get_node(tree.get_node(tree.leaves()[i].predecessor(tree.identifier)).predecessor(tree.identifier)).identifier)\n",
    "\n",
    "    counter = Counter(parent_ids)\n",
    "\n",
    "    grandparent_w_more_than_one_leaves = {k:v for k, v in counter.items() if v > 1}\n",
    "\n",
    "    for gk in grandparent_w_more_than_one_leaves.keys():\n",
    "        current_node_leaves = tree.leaves(gk)\n",
    "        current_leaves_tags = [leaf.tag for leaf in current_node_leaves]\n",
    "        if len(set(current_leaves_tags)) == 1:\n",
    "            parent_of_g = tree.get_node(gk).predecessor(tree.identifier)\n",
    "            tree.move_node(current_node_leaves[0].identifier, parent_of_g)\n",
    "            tree.remove_node(gk)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dtree_cad = id3(cad1, Tree())\n",
    "\n",
    "dtree_fishing = id3(fishing1, Tree())\n",
    "\n",
    "dtree_contact_lenses = id3(contact_lenses1, Tree())\n",
    "\n",
    "dtree_caesarian = id3(caesarian1, Tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "current_tag = dtree_cad.get_node(dtree_cad.root).tag"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "'Normal'"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_tag = cad1.loc[0,current_tag]\n",
    "current_tag"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "current_values = dtree_cad.get_node(dtree_cad.root).successors(dtree_cad.identifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "['Borderline', 'High', 'Normal']"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dtree_cad.get_node(i).tag for i in current_values]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "'No'"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree_cad.get_node(dtree_cad.get_node(current_values[2]).successors(dtree_cad.identifier)[0]).tag"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def tree_predict(tree, df):\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesterol\n",
      "├── Borderline\n",
      "│   └── Gender\n",
      "│       ├── F\n",
      "│       │   └── No\n",
      "│       └── M\n",
      "│           └── No\n",
      "├── High\n",
      "│   └── Gender\n",
      "│       ├── F\n",
      "│       │   └── Yes\n",
      "│       └── M\n",
      "│           └── Yes\n",
      "└── Normal\n",
      "    └── No\n",
      "\n",
      "Sky\n",
      "├── Cloudy\n",
      "│   └── Yes\n",
      "├── Rainy\n",
      "│   └── Air\n",
      "│       ├── Cool\n",
      "│       │   └── No\n",
      "│       └── Warm\n",
      "│           └── Wind\n",
      "│               ├── Strong\n",
      "│               │   └── Yes\n",
      "│               └── Weak\n",
      "│                   └── No\n",
      "└── Sunny\n",
      "    └── Wind\n",
      "        ├── Strong\n",
      "        │   └── Yes\n",
      "        └── Weak\n",
      "            └── Water\n",
      "                ├── Cold\n",
      "                │   └── No\n",
      "                ├── Moderate\n",
      "                │   └── Yes\n",
      "                └── Warm\n",
      "                    └── No\n",
      "\n",
      "tearrate\n",
      "├── normal\n",
      "│   └── astigmatism\n",
      "│       ├── no\n",
      "│       │   └── age\n",
      "│       │       ├── pre-presbyopic\n",
      "│       │       │   └── soft\n",
      "│       │       ├── presbyopic\n",
      "│       │       │   └── prescription\n",
      "│       │       │       ├── hypermetrope\n",
      "│       │       │       │   └── soft\n",
      "│       │       │       └── myope\n",
      "│       │       │           └── none\n",
      "│       │       └── young\n",
      "│       │           └── soft\n",
      "│       └── yes\n",
      "│           └── prescription\n",
      "│               ├── hypermetrope\n",
      "│               │   └── age\n",
      "│               │       ├── pre-presbyopic\n",
      "│               │       │   └── none\n",
      "│               │       ├── presbyopic\n",
      "│               │       │   └── none\n",
      "│               │       └── young\n",
      "│               │           └── hard\n",
      "│               └── myope\n",
      "│                   └── hard\n",
      "└── reduced\n",
      "    └── none\n",
      "\n",
      "Cardiac\n",
      "├── abnormal\n",
      "│   └── BP\n",
      "│       ├── high\n",
      "│       │   └── Delivery\n",
      "│       │       ├── late\n",
      "│       │       │   └── Age\n",
      "│       │       │       ├── Age<34.5\n",
      "│       │       │       │   └── no\n",
      "│       │       │       └── Age>=34.5\n",
      "│       │       │           └── yes\n",
      "│       │       ├── normal\n",
      "│       │       │   └── yes\n",
      "│       │       └── premature\n",
      "│       │           └── yes\n",
      "│       ├── low\n",
      "│       │   └── yes\n",
      "│       └── normal\n",
      "│           └── Age\n",
      "│               ├── Age<26.5\n",
      "│               │   └── no\n",
      "│               └── Age>=26.5\n",
      "│                   └── Delivery\n",
      "│                       ├── late\n",
      "│                       │   └── no\n",
      "│                       └── normal\n",
      "│                           └── yes\n",
      "└── normal\n",
      "    └── Age\n",
      "        ├── Age<22.0\n",
      "        │   └── BP\n",
      "        │       ├── high\n",
      "        │       │   └── yes\n",
      "        │       ├── low\n",
      "        │       │   └── yes\n",
      "        │       └── normal\n",
      "        │           └── Delivery\n",
      "        │               └── normal\n",
      "        │                   └── yes\n",
      "        └── Age>=22.0\n",
      "            └── Delivery\n",
      "                ├── late\n",
      "                │   └── BP\n",
      "                │       ├── high\n",
      "                │       │   └── no\n",
      "                │       ├── low\n",
      "                │       │   └── no\n",
      "                │       └── normal\n",
      "                │           └── no\n",
      "                ├── normal\n",
      "                │   └── BP\n",
      "                │       ├── high\n",
      "                │       │   └── no\n",
      "                │       ├── low\n",
      "                │       │   └── yes\n",
      "                │       └── normal\n",
      "                │           └── no\n",
      "                └── premature\n",
      "                    └── BP\n",
      "                        ├── high\n",
      "                        │   └── yes\n",
      "                        ├── low\n",
      "                        │   └── no\n",
      "                        └── normal\n",
      "                            └── no\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtree_cad.show()\n",
    "dtree_fishing.show()\n",
    "dtree_contact_lenses.show()\n",
    "dtree_caesarian.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pygraphviz as pgv\n",
    "\n",
    "def draw_tree(tr, name):\n",
    "    infile = '../outputs/' + name + '.dot'\n",
    "    outfile = '../outputs/' + name + '.png'\n",
    "    tr.to_graphviz(infile)\n",
    "    g = pgv.AGraph(infile)\n",
    "    g.layout(prog=\"dot\")\n",
    "    g.draw(outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "draw_tree(dtree_cad, 'cad')\n",
    "draw_tree(dtree_fishing, 'fishing')\n",
    "draw_tree(dtree_contact_lenses, 'contact_lenses')\n",
    "draw_tree(dtree_caesarian, 'caesarian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_if_then_rules(tr):\n",
    "    if_then_rules = []\n",
    "    ptl = tr.paths_to_leaves()\n",
    "    for i in range(len(ptl)):\n",
    "        temp_list = []\n",
    "        for j in range(len(ptl[i])):\n",
    "            temp_list.append(tr.get_node(ptl[i][j]).tag)\n",
    "        if_then_rules.append(temp_list)\n",
    "\n",
    "    for s in range(len(if_then_rules)):\n",
    "        if_then_rules[s] = [str(i)+'='+str(j) for i,j in itertools.zip_longest(if_then_rules[s][0::2], if_then_rules[s][1::2])]\n",
    "        if_then_rules[s][-1] = if_then_rules[s][-1].split('=')[0]\n",
    "\n",
    "    if_then_rules_formatted = []\n",
    "    for s in range(len(if_then_rules)):\n",
    "        joined = ' -> '.join(if_then_rules[s])\n",
    "        if_then_rules_formatted.append(joined)\n",
    "\n",
    "\n",
    "\n",
    "    return if_then_rules_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cad_rules = get_if_then_rules(dtree_cad)\n",
    "\n",
    "fishing_rules = get_if_then_rules(dtree_fishing)\n",
    "# fishing_rules\n",
    "contact_lenses_rules = get_if_then_rules(dtree_contact_lenses)\n",
    "# contact_lenses_rules\n",
    "caesarian_rules = get_if_then_rules(dtree_caesarian)\n",
    "# caesarian_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['Cholesterol=Borderline -> Gender=F -> No',\n 'Cholesterol=Borderline -> Gender=M -> No',\n 'Cholesterol=High -> Gender=F -> Yes',\n 'Cholesterol=High -> Gender=M -> Yes',\n 'Cholesterol=Normal -> No']"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cad_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['Sky=Cloudy -> Yes',\n 'Sky=Rainy -> Air=Cool -> No',\n 'Sky=Rainy -> Air=Warm -> Wind=Strong -> Yes',\n 'Sky=Rainy -> Air=Warm -> Wind=Weak -> No',\n 'Sky=Sunny -> Wind=Strong -> Yes',\n 'Sky=Sunny -> Wind=Weak -> Water=Cold -> No',\n 'Sky=Sunny -> Wind=Weak -> Water=Moderate -> Yes',\n 'Sky=Sunny -> Wind=Weak -> Water=Warm -> No']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fishing_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['tearrate=normal -> astigmatism=no -> age=pre-presbyopic -> soft',\n 'tearrate=normal -> astigmatism=no -> age=presbyopic -> prescription=hypermetrope -> soft',\n 'tearrate=normal -> astigmatism=no -> age=presbyopic -> prescription=myope -> none',\n 'tearrate=normal -> astigmatism=no -> age=young -> soft',\n 'tearrate=normal -> astigmatism=yes -> prescription=hypermetrope -> age=pre-presbyopic -> none',\n 'tearrate=normal -> astigmatism=yes -> prescription=hypermetrope -> age=presbyopic -> none',\n 'tearrate=normal -> astigmatism=yes -> prescription=hypermetrope -> age=young -> hard',\n 'tearrate=normal -> astigmatism=yes -> prescription=myope -> hard',\n 'tearrate=reduced -> none']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contact_lenses_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['Cardiac=abnormal -> BP=high -> Delivery=late -> Age=Age<34.5 -> no',\n 'Cardiac=abnormal -> BP=high -> Delivery=late -> Age=Age>=34.5 -> yes',\n 'Cardiac=abnormal -> BP=high -> Delivery=normal -> yes',\n 'Cardiac=abnormal -> BP=high -> Delivery=premature -> yes',\n 'Cardiac=abnormal -> BP=low -> yes',\n 'Cardiac=abnormal -> BP=normal -> Age=Age<26.5 -> no',\n 'Cardiac=abnormal -> BP=normal -> Age=Age>=26.5 -> Delivery=late -> no',\n 'Cardiac=abnormal -> BP=normal -> Age=Age>=26.5 -> Delivery=normal -> yes',\n 'Cardiac=normal -> Age=Age<22.0 -> BP=high -> yes',\n 'Cardiac=normal -> Age=Age<22.0 -> BP=low -> yes',\n 'Cardiac=normal -> Age=Age<22.0 -> BP=normal -> Delivery=normal -> yes',\n 'Cardiac=normal -> Age=Age>=22.0 -> Delivery=late -> BP=high -> no',\n 'Cardiac=normal -> Age=Age>=22.0 -> Delivery=late -> BP=low -> no',\n 'Cardiac=normal -> Age=Age>=22.0 -> Delivery=late -> BP=normal -> no',\n 'Cardiac=normal -> Age=Age>=22.0 -> Delivery=normal -> BP=high -> no',\n 'Cardiac=normal -> Age=Age>=22.0 -> Delivery=normal -> BP=low -> yes',\n 'Cardiac=normal -> Age=Age>=22.0 -> Delivery=normal -> BP=normal -> no',\n 'Cardiac=normal -> Age=Age>=22.0 -> Delivery=premature -> BP=high -> yes',\n 'Cardiac=normal -> Age=Age>=22.0 -> Delivery=premature -> BP=low -> no',\n 'Cardiac=normal -> Age=Age>=22.0 -> Delivery=premature -> BP=normal -> no']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caesarian_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Chenfeng (Aaron) Hao"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}